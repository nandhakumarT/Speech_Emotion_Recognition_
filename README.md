## Speech_Emotion_Recognition_
This project used Convolutional Neural Networks and LSTM to classify opposing emotions. Separate the speech by the speaker's gender to investigate the relationship between gender and the emotional content of speech. There are a variety of temporal and spectral features that can be extracted from human speech. We use statistics relating to the pitch, Mel Frequency Cepstral Coefficients (MFCCs), and Formants of speech as inputs to classification algorithms. The emotion recognition accuracy of these experiments allows us to explain which features carry the most emotional information. Marketing companies can use it to suggest products for their customers based on their emotions. 
